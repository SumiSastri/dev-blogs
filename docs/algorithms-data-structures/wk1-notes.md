__Why data structures__

- Access, store and process the data
- Formal definition and abstract definition
- Money charged for transaction of data - processing and transport

__What is a data structure__

- Difference between structured data and data structures
- Connecting data - accurate data
- permananent data has a static structure that is stable (int) vs an address
- Smaller 4 bytes of data

Search is an algorithm
Manage data
Solve problems
ICT (information-communication-tech)

- Protection, movement, storage of data
- LLM - large language model
- following instructions vs decision making (critical thinking)

- a way to organise a collection of data that is related in some way (to store, access and process)
- language dependent, new structures can not be created by developers
- with OOP possible - as classes will allow new data structures but maybe not data types
- virtually all data structures have underlying mathematical structures
- in processing data there is an "operational" view of the data
- storing data in memory has an "internal representation" of this data

__Types of data structures__

- Linear (sequential)
- Non-linear (non-sequential)
- Static (fixed size, sequential)
- Dynamic (no fixed size - data can be added or removed)
- Indexed (key-value pairs)
- Linked (non-indexed)

__Data and memory management__

Static data - fixed and small, can waste memory space, leave gaps and fragmentation of space
Dynamic - unknown variable data needs to be dealt with in compile time, data can shrink or grow in runtime

The 'new' key word allocates memory for new objects/ classes with a stack pointer referring to its address in the memory location

__Abstract Data Type - ADT__

- defined by data hiding or encapsulation
- interfaces and public methods access the data
- ADTs allow flexible manipulation of underlying data without modification to structure of the data
- ADTs change implementation not structure

__Algorithms__

A set of instructions performed in a sequence to secure a result
Efficiency based on
Time
Space

Analysis depends on
resources (size, complexity) and relative costs (efficiency, running time, storage required)

Types

- Brute force (slow)
- Divide and conquer (break up and solve in steps)
- Greedy (optimisation issues, dont always lead to a solution)

Alogrithms - training the computer to think
Claudia?

__Order of complexity of data__

- Efficiency or the order of complexity is often denoted as `n` or the amount/ size of data
- With graphs the vertices - or nodes more important/ the number of edges

Time is denoted with `t` or the length of time the program needs to run for

t(n) - is time and size of data
Big O
Upper bound - highest t(n) value or growth rate - worst case (steeper the gradient the worse the case)

Big Theta
Average bound - average case

Big Omega
Lower bound - is best case

LIFO-FIFO are alogrithms - how you manipulate data 
Queue FIFO

- Divide and conquer (break up and solve in steps)
Divide and conquer is a tree - top of the tree
Segment the tree

__BInary tree__

2 nodes max
right side data is always smaller than left side
Data divided right register first
Easy to sort difficult to allocate

__Graph structure__
Vertices and edges 

Space in the cache - dynamic memory/ place for swap pages

Abstract data class - objects/ interfaces/ classes/ functions

ADT - DONT KNOW THE DATA type yet
Unknown and unclear but expect for future for discovery and implementation

__Brute force__

Try as many times as you require to break open - phone/ email password/ 
Not about efficiency about getting through
3 digits
1/10 or 10 to the pow of 3 - 1,000 attempts 
Add alphabets
26 to the power of 3
10 to the power of 3

Quantum computers bec of vectors unlock patterns quicker than others - quantum chip (why?)

If you know vectors with brute force - then cracking the code is easy
Slow - time not efficient

__Divide and conquer__

Break down into subtasks a big task
Disadvantage is difficult to order
Binary tree is divide and conquer but restricted to 2 elements
Divide and conquer is with divide by 2 in the beginning but n elements on either side - binary have to reduce down to 2


__Merge sort__

Start from the middle and divide and merge incorrect answers then only deal with the unmerged data
Subgroups are sorted and merged

__Greedy algo__

50 pound change to 15 is 20/10/5 
Many choices - choose the biggest and sort to the smallest
Greedy - sees first choice and easiest
Does not see the whole picture
Shortest - is greedy choice 

__Big O__
Type of complexity
Time is constant

Linear search - n times
o(n) - complexity goes o = n (the number of times of the data)
nested loops
quadratic o(n2)
cubic - 3 loops
o(n3)
Increase in data - increase in time
Small data - no significatnt different

n = 2xn

__Divide Conquer__

Binary search tree
log2(n)
Best case logarathim

What is the difference between big o and worst case?

Complexity table and the o vs n

7 types of big o